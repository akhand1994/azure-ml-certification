{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Azure Machine Learning Pipeline\n",
    "\n",
    "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a *pipeline* that can be run on one or more compute targets, either on-demand by a user, from an automated build process, or on a schedule.\n",
    "\n",
    "In this lab, you'll bring together all of these elements to create a simple pipeline that trains and registers a model.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.18.0 to work with nikhilsuthardp100\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Training Data\n",
    "\n",
    "You can use local data files to train a model, but when running training workloads automatically on cloud-based compute, it makes more sense to store the data centrally in the cloud and ingest it into the training script wherever it happens to be running.\n",
    "\n",
    "In this lab, you'll upload the training data to a *datastore* and define a *dataset* that can be used to access the data from a training script. For simplicity, you'll upload the data to the default datastore for your Azure Machine Learning workspace - this is an Azure Storage blob container that was created when you provisioned the workspace. In a real solution, you'd likely register a datastore that references the cloud location where you typically store your data. You'll then create a *tabular* dataset that references the CSV files you uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scripts for Pipeline Steps\n",
    "\n",
    "Now you're ready to start work on your pipeline. Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an Auto ML training estimator or a data transfer step that copies data from one location to another. Each step can run in its own compute context.\n",
    "\n",
    "In this exercise, you'll build a simple pipeline that contains an estimator step (to train a model) and a Python script step (to register the trained model). Start by creating a folder to contain the scripts for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will use an estimator to run a training script. The code in the following cell creates this script for you. Note that the script includes a parameter named **output_folder**, which references the folder where the trained model should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path to the folder where the model was saved by the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/register_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "The pipeline will eventually be published and run on-demand, so it needs a compute environment in which to run. In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, you need a compute target. In this case, you create an Azure Machine Learning compute cluster in your workspace (or use an existing one if you have created it previously).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to a unique name for your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"nikhilvmcluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute will require a Python environment with the necessary package dependencies installed, so we'll create a run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\n",
    "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Pipeline\n",
    "\n",
    "Now you're ready to define and run the pipeline.\n",
    "\n",
    "First you need to define the steps for the pipeline, and any data references that need to passed between them. In this case, the first step must write the model to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **PipelineData** object is a special kind of data reference that is used to pass data from the output of one pipeline step to the input of another, creating a dependency between them. You'll create one and use it as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_diabetes.py')\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_diabetes.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now you're ready to build the pipeline from the steps you've defined and run it as an experiment.\n",
    "\n",
    "> **Note**: This may take a while. The training cluster must be started and configured with the Python environment before the scripts can be run. Now might be a good time to take a coffee break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [590f6e0b][07bd421b-156f-4fcb-9659-c969f786c8f1], (This step will run and generate new outputs)Created step Register Model [c136bfe3][5538de8b-7f8a-40bc-9bb0-8eb9268fae56], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun fa014266-d11a-4f39-b299-35392b892075\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fa014266-d11a-4f39-b299-35392b892075?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "Pipeline submitted for execution.\n",
      "PipelineRunId: fa014266-d11a-4f39-b299-35392b892075\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fa014266-d11a-4f39-b299-35392b892075?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 327d0507-d004-4017-9fde-f49b4761a284\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/327d0507-d004-4017-9fde-f49b4761a284?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/11/25 10:15:28 Downloading source code...\n",
      "2020/11/25 10:15:29 Finished downloading source code\n",
      "StepRun( Train Model ) Status: Running\n",
      "2020/11/25 10:15:30 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/11/25 10:15:30 Successfully set up Docker network: acb_default_network\n",
      "2020/11/25 10:15:30 Setting up Docker configuration...\n",
      "2020/11/25 10:15:31 Successfully set up Docker configuration\n",
      "2020/11/25 10:15:31 Logging in to registry: ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      "2020/11/25 10:15:32 Successfully logged into ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      "2020/11/25 10:15:32 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/11/25 10:15:32 Scanning for dependencies...\n",
      "2020/11/25 10:15:33 Successfully scanned dependencies\n",
      "2020/11/25 10:15:33 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon     64kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "Digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      " ---> 287916b809d9\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 9c77a3ff77b4\n",
      "Removing intermediate container 9c77a3ff77b4\n",
      " ---> c06d0a0ba09b\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in cb12595086ba\n",
      "Removing intermediate container cb12595086ba\n",
      " ---> 4b644577b247\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in a1b07ca59e14\n",
      "Removing intermediate container a1b07ca59e14\n",
      " ---> cf7562f44c78\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> e95cae57622b\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in b3db34c34ff5\n",
      "Removing intermediate container b3db34c34ff5\n",
      " ---> f96febbf39d3\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> f50ec77b41de\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 2c0a27c8775c\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ####9      |  50% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ######1    |  62% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  | 2          |   2% \n",
      "mkl-2019.4           | 204.1 MB  | 5          |   6% \n",
      "mkl-2019.4           | 204.1 MB  | 8          |   9% \n",
      "mkl-2019.4           | 204.1 MB  | #2         |  12% \n",
      "mkl-2019.4           | 204.1 MB  | #5         |  16% \n",
      "mkl-2019.4           | 204.1 MB  | #8         |  19% \n",
      "mkl-2019.4           | 204.1 MB  | ##2        |  22% \n",
      "mkl-2019.4           | 204.1 MB  | ##5        |  26% \n",
      "mkl-2019.4           | 204.1 MB  | ##9        |  30% \n",
      "mkl-2019.4           | 204.1 MB  | ###3       |  34% \n",
      "mkl-2019.4           | 204.1 MB  | ###7       |  38% \n",
      "mkl-2019.4           | 204.1 MB  | ####1      |  42% \n",
      "mkl-2019.4           | 204.1 MB  | ####5      |  46% \n",
      "mkl-2019.4           | 204.1 MB  | #####      |  50% \n",
      "mkl-2019.4           | 204.1 MB  | #####4     |  54% \n",
      "mkl-2019.4           | 204.1 MB  | #####7     |  58% \n",
      "mkl-2019.4           | 204.1 MB  | ######1    |  62% \n",
      "mkl-2019.4           | 204.1 MB  | ######5    |  66% \n",
      "mkl-2019.4           | 204.1 MB  | ######9    |  70% \n",
      "mkl-2019.4           | 204.1 MB  | #######3   |  74% \n",
      "mkl-2019.4           | 204.1 MB  | #######7   |  78% \n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | ##9        |  30% \n",
      "scipy-1.5.2          | 18.5 MB   | #######2   |  72% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #8         |  18% \n",
      "python-3.6.2         | 27.0 MB   | #####      |  51% \n",
      "python-3.6.2         | 27.0 MB   | ########   |  81% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   | ####4      |  44% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | #########  |  91% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.wqhdyw36.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults~=1.18.0\n",
      "  Downloading azureml_defaults-1.18.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting azureml-dataprep[pandas]\n",
      "  Downloading azureml_dataprep-2.6.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.18.0\n",
      "  Downloading azureml_dataset_runtime-1.18.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-core~=1.18.0\n",
      "  Downloading azureml_core-1.18.0.post3-py3-none-any.whl (2.1 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.5.0a,>=1.4.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.4.0-cp36-cp36m-manylinux2010_x86_64.whl (7.9 MB)\n",
      "Collecting azureml-dataprep-native<27.0.0,>=26.0.0\n",
      "  Downloading azureml_dataprep_native-26.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.19-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 2)) (1.1.3)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0; extra == \"pandas\"\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 2)) (1.19.1)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.18.0->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.5-py2.py3-none-any.whl (55 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.18.0->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.18.0->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.4.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.3.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Collecting PyJWT<2.0.0\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting pyopenssl<20.0.0\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.6.0-py2.py3-none-any.whl (50 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.9.0-py2.py3-none-any.whl (124 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.18.0->-r /azureml-environment-setup/condaenv.wqhdyw36.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-3.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.4-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: json-logging-py, liac-arff, fusepy\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=4209af421fb3ed62565dfa281207819e9e7fd735c9db84e25ed35c9a9a9f9327\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=5a973dcd17443b86d81b8e3bfcd206f7324df6491597ef8d76cf2ffb6c15895a\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=33071d7163f55bb14be8bd5b5572ddb5d025faecd266e1bafe3d602454421312\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built json-logging-py liac-arff fusepy\n",
      "Installing collected packages: json-logging-py, werkzeug, applicationinsights, click, MarkupSafe, Jinja2, itsdangerous, flask, PyJWT, pycparser, cffi, cryptography, chardet, urllib3, idna, requests, adal, liac-arff, dill, azureml-model-management-sdk, configparser, pyarrow, portalocker, msal, msal-extensions, azure-core, azure-identity, azureml-dataprep-rslex, azureml-dataprep-native, cloudpickle, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, gunicorn, websocket-client, docker, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-common, azure-graphrbac, zipp, importlib-metadata, jsonpickle, azure-mgmt-resource, pyopenssl, pyasn1, ndg-httpsclient, backports.weakref, backports.tempfile, azure-mgmt-authorization, azure-mgmt-storage, ruamel.yaml.clib, ruamel.yaml, jeepney, SecretStorage, jmespath, azure-mgmt-keyvault, pathspec, azure-mgmt-containerregistry, contextlib2, azureml-core, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.3.0 adal-1.2.5 applicationinsights-0.11.9 azure-common-1.1.26 azure-core-1.9.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-10.3.0 azure-mgmt-storage-11.2.0 azureml-core-1.18.0.post3 azureml-dataprep-2.6.0 azureml-dataprep-native-26.0.0 azureml-dataprep-rslex-1.4.0 azureml-dataset-runtime-1.18.0 azureml-defaults-1.18.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.4 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.2.1 dill-0.3.3 distro-1.5.0 docker-4.4.0 dotnetcore2-2.1.19 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-3.1.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.5.0 msal-1.6.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pathspec-0.8.1 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 requests-2.25.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 urllib3-1.26.2 websocket-client-0.57.0 werkzeug-1.0.1 zipp-3.4.0\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 2c0a27c8775c\n",
      " ---> 845ca95408bf\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin:$PATH\n",
      " ---> Running in 21a348e1a5e4\n",
      "Removing intermediate container 21a348e1a5e4\n",
      " ---> b17d6102932e\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419\n",
      " ---> Running in f42a2668a734\n",
      "Removing intermediate container f42a2668a734\n",
      " ---> a9d35bbf0c72\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 31bea22253c3\n",
      "Removing intermediate container 31bea22253c3\n",
      " ---> ea73b71350e0\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 7addcc6bf1bc\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 0dcc02d26bdd\n",
      "Removing intermediate container 0dcc02d26bdd\n",
      " ---> 139f39b26121\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 69925359edfe\n",
      "Removing intermediate container 69925359edfe\n",
      " ---> 7679ce2d36ec\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in d4781dbe8d8d\n",
      "Removing intermediate container d4781dbe8d8d\n",
      " ---> 84bb075ea7b6\n",
      "Successfully built 84bb075ea7b6\n",
      "Successfully tagged ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020/11/25 10:19:00 Successfully executed container: acb_step_0\n",
      "2020/11/25 10:19:00 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/11/25 10:19:00 Pushing image: ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest, attempt 1\n",
      "The push refers to repository [ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37]\n",
      "01710fadaac9: Preparing\n",
      "55cf4caf203a: Preparing\n",
      "1cb0558a254b: Preparing\n",
      "7b0d4c1febad: Preparing\n",
      "8aa70fd27600: Preparing\n",
      "1f6539577c3d: Preparing\n",
      "13e378616f24: Preparing\n",
      "efc99d952c3d: Preparing\n",
      "9e292a80b88a: Preparing\n",
      "5e1805eb9eb5: Preparing\n",
      "8dab94e6d05c: Preparing\n",
      "2817caf0a082: Preparing\n",
      "aece08fd27fc: Preparing\n",
      "4caea5ef1f0b: Preparing\n",
      "dcc0cc99372e: Preparing\n",
      "87c128261339: Preparing\n",
      "41a253a417e6: Preparing\n",
      "e06660e80cf4: Preparing\n",
      "1f6539577c3d: Waiting\n",
      "13e378616f24: Waiting\n",
      "efc99d952c3d: Waiting\n",
      "9e292a80b88a: Waiting\n",
      "5e1805eb9eb5: Waiting\n",
      "8dab94e6d05c: Waiting\n",
      "2817caf0a082: Waiting\n",
      "aece08fd27fc: Waiting\n",
      "4caea5ef1f0b: Waiting\n",
      "dcc0cc99372e: Waiting\n",
      "87c128261339: Waiting\n",
      "41a253a417e6: Waiting\n",
      "e06660e80cf4: Waiting\n",
      "7b0d4c1febad: Pushed\n",
      "1cb0558a254b: Pushed\n",
      "01710fadaac9: Pushed\n",
      "8aa70fd27600: Pushed\n",
      "1f6539577c3d: Pushed\n",
      "13e378616f24: Pushed\n",
      "efc99d952c3d: Pushed\n",
      "9e292a80b88a: Pushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aece08fd27fc: Pushed\n",
      "5e1805eb9eb5: Pushed\n",
      "dcc0cc99372e: Pushed\n",
      "2817caf0a082: Pushed\n",
      "87c128261339: Pushed\n",
      "41a253a417e6: Pushed\n",
      "8dab94e6d05c: Pushed\n",
      "4caea5ef1f0b: Pushed\n",
      "e06660e80cf4: Pushed\n",
      "\n",
      "55cf4caf203a: Pushed\n",
      "latest: digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92 size: 4095\n",
      "2020/11/25 10:21:25 Successfully pushed image: ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020/11/25 10:21:25 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 208.160232)\n",
      "2020/11/25 10:21:25 Populating digests for step ID: acb_step_0...\n",
      "2020/11/25 10:21:27 Successfully populated digests for step ID: acb_step_0\n",
      "2020/11/25 10:21:27 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 145.058186)\n",
      "2020/11/25 10:21:27 The following dependencies were found:\n",
      "2020/11/25 10:21:27 \n",
      "- image:\n",
      "    registry: ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      "    repository: azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      "    tag: latest\n",
      "    digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20200821.v1\n",
      "    digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "  git: {}\n",
      "\n",
      "Run ID: ch2 was successful after 6m0s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "========================================================================================================================\n",
      "2020-11-25T10:25:49Z Starting output-watcher...\n",
      "2020-11-25T10:25:49Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-11-25T10:25:50Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-25T10:25:50Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "2ac0c1c5efb1: Pulling fs layer\n",
      "f8346564ee8f: Pulling fs layer\n",
      "61e1bbaea901: Pulling fs layer\n",
      "969cf6840a6d: Pulling fs layer\n",
      "20c161d5909e: Pulling fs layer\n",
      "1f63192e8db7: Pulling fs layer\n",
      "5335952fa8d3: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "2ac0c1c5efb1: Waiting\n",
      "f8346564ee8f: Waiting\n",
      "61e1bbaea901: Waiting\n",
      "969cf6840a6d: Waiting\n",
      "20c161d5909e: Waiting\n",
      "1f63192e8db7: Waiting\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "73eef93b7466: Waiting\n",
      "d5a54c1fb97f: Waiting\n",
      "a613a9b4553c: Verifying Checksum\n",
      "a613a9b4553c: Download complete\n",
      "acc000f01536: Verifying Checksum\n",
      "acc000f01536: Download complete\n",
      "73eef93b7466: Verifying Checksum\n",
      "73eef93b7466: Download complete\n",
      "8e097b52bfb8: Verifying Checksum\n",
      "8e097b52bfb8: Download complete\n",
      "1536f6ca931b: Verifying Checksum\n",
      "1536f6ca931b: Download complete\n",
      "d7b631d130cb: Verifying Checksum\n",
      "d7b631d130cb: Download complete\n",
      "d5a54c1fb97f: Verifying Checksum\n",
      "d5a54c1fb97f: Download complete\n",
      "75ffe8dfb222: Verifying Checksum\n",
      "75ffe8dfb222: Download complete\n",
      "5335952fa8d3: Verifying Checksum\n",
      "5335952fa8d3: Download complete\n",
      "96fa3cc6fe10: Verifying Checksum\n",
      "96fa3cc6fe10: Download complete\n",
      "e428dd9daa94: Verifying Checksum\n",
      "e428dd9daa94: Download complete\n",
      "2ac0c1c5efb1: Verifying Checksum\n",
      "2ac0c1c5efb1: Download complete\n",
      "f8346564ee8f: Verifying Checksum\n",
      "f8346564ee8f: Download complete\n",
      "61e1bbaea901: Verifying Checksum\n",
      "61e1bbaea901: Download complete\n",
      "969cf6840a6d: Verifying Checksum\n",
      "969cf6840a6d: Download complete\n",
      "1f63192e8db7: Verifying Checksum\n",
      "1f63192e8db7: Download complete\n",
      "8e097b52bfb8: Pull complete\n",
      "86b4bf2f8d5f: Verifying Checksum\n",
      "86b4bf2f8d5f: Download complete\n",
      "a613a9b4553c: Pull complete\n",
      "acc000f01536: Pull complete\n",
      "73eef93b7466: Pull complete\n",
      "d5a54c1fb97f: Pull complete\n",
      "1536f6ca931b: Pull complete\n",
      "20c161d5909e: Verifying Checksum\n",
      "20c161d5909e: Download complete\n",
      "d7b631d130cb: Pull complete\n",
      "75ffe8dfb222: Pull complete\n",
      "86b4bf2f8d5f: Pull complete\n",
      "5335952fa8d3: Pull complete\n",
      "96fa3cc6fe10: Pull complete\n",
      "e428dd9daa94: Pull complete\n",
      "2ac0c1c5efb1: Pull complete\n",
      "f8346564ee8f: Pull complete\n",
      "61e1bbaea901: Pull complete\n",
      "969cf6840a6d: Pull complete\n",
      "20c161d5909e: Pull complete\n",
      "1f63192e8db7: Pull complete\n",
      "Digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92\n",
      "Status: Downloaded newer image for ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020-11-25T10:26:53Z Check if container 327d0507-d004-4017-9fde-f49b4761a284 already exist exited with 0, \n",
      "\n",
      "bf34a655fca71370263628f8bd83ca904238a9cb942d479dcf2e5a87e62d000b\n",
      "2020/11/25 10:27:04 Starting App Insight Logger for task:  containerSetup\n",
      "2020/11/25 10:27:04 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      "2020/11/25 10:27:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:27:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:27:04 sshd inside container not required for job, skipping setup.\n",
      "2020/11/25 10:27:05 All App Insights Logs was send successfully\n",
      "2020-11-25T10:27:05Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/11/25 10:27:10 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2020/11/25 10:27:10 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2020-11-25T10:27:11.746872] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train_diabetes.py', '--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/327d0507-d004-4017-9fde-f49b4761a284/mounts/workspaceblobstore/azureml/327d0507-d004-4017-9fde-f49b4761a284/model_folder'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 102\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/327d0507-d004-4017-9fde-f49b4761a284/mounts/workspaceblobstore/azureml/327d0507-d004-4017-9fde-f49b4761a284\n",
      "Preparing to call script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/327d0507-d004-4017-9fde-f49b4761a284/mounts/workspaceblobstore/azureml/327d0507-d004-4017-9fde-f49b4761a284/model_folder']\n",
      "After variable expansion, calling script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/327d0507-d004-4017-9fde-f49b4761a284/mounts/workspaceblobstore/azureml/327d0507-d004-4017-9fde-f49b4761a284/model_folder']\n",
      "\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.9\n",
      "AUC: 0.8844360427923883\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 102\n",
      "\n",
      "\n",
      "[2020-11-25T10:27:29.340799] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.1450514793395996 seconds\n",
      "[2020-11-25T10:27:30.710748] Finished context manager injector.\n",
      "2020/11/25 10:27:35 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2020/11/25 10:27:35 Process Exiting with Code:  0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "===============================================================================================================\n",
      "[2020-11-25T10:27:35.630471] Entering job release\n",
      "[2020-11-25T10:27:36.611301] Starting job release\n",
      "[2020-11-25T10:27:36.612295] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 330\n",
      "[2020-11-25T10:27:36.613121] job release stage : upload_datastore starting...\n",
      "[2020-11-25T10:27:36.616375] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-25T10:27:36.616656] job release stage : execute_job_release starting...\n",
      "[2020-11-25T10:27:36.624810] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-25T10:27:36.624878] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-25T10:27:36.625634] Entering context manager injector.\n",
      "[2020-11-25T10:27:36.881517] job release stage : upload_datastore completed...\n",
      "[2020-11-25T10:27:36.889367] job release stage : send_run_telemetry starting...\n",
      "[2020-11-25T10:27:37.404987] job release stage : execute_job_release completed...\n",
      "[2020-11-25T10:27:38.554008] job release stage : send_run_telemetry completed...\n",
      "[2020-11-25T10:27:38.554474] Job release is complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '327d0507-d004-4017-9fde-f49b4761a284', 'target': 'nikhilvmcluster', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:25:41.472542Z', 'endTimeUtc': '2020-11-25T10:27:43.989187Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '5af7ce67-c6d7-4d64-96ee-7820e11f7625', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '07bd421b-156f-4fcb-9659-c969f786c8f1', 'azureml.nodeid': '590f6e0b', 'azureml.pipelinerunid': 'fa014266-d11a-4f39-b299-35392b892075', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '47094f00-3593-45f5-97d5-f8ebb5db829c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'nikhilvmcluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/327d0507-d004-4017-9fde-f49b4761a284/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': '47094f00-3593-45f5-97d5-f8ebb5db829c', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.18.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas'], 'name': 'azureml_76d0c57fc1c2b25401278bcbc2779419'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=t6qBd5yYA7t02tUcTdIiREv2OTaPL%2FlsS8QUD%2BQbnWQ%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=aqHRFO7vp57Ceeo3k7NP4mUwKgyL1murgO085BJicGw%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=8xfj1T5IfSmTEEGOp1CHYyNowK8c82FTkFAx9qh09lA%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=g40eoHdFFJ5TVd6kxmqDFuyP4FP%2BPjV6QslsRGGrHI8%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=vnjtKUCtMKhJSAlT3259DWsZKuTy9D0KXkoI3BcK%2FRI%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/process_info.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=JGrhjNtSL0DhgdJyxh3TI7z7ZulorG0CshGCEOfqZ5M%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'azureml-logs/process_status.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=U9Tg%2BdkMO%2FUaoEk%2FQtzBQt8Lr9BJH1nE5%2Fwkjg5z1Kw%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/102_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/102_azureml.log?sv=2019-02-02&sr=b&sig=XtwFZaCOhc4gTB80bnYnJJCoAYIspyhvXmERob4Ko%2B8%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=%2BPI6NS%2BFoFJtjp7moqBVPOXDUhYq6WM8R7c4JhqyIUM%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=0sGb%2BUG0PdBVDKZpRYBdfOygmp1XrjdXPz97%2F2d2Exc%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/dataprep/engine_spans_l_9b673a52-e3e1-4129-a2b2-0dc0d739809c.jsonl': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/dataprep/engine_spans_l_9b673a52-e3e1-4129-a2b2-0dc0d739809c.jsonl?sv=2019-02-02&sr=b&sig=49G85Z53Dexxx7Ul52hu6rp1LPdHJEnBUNcqnl2AJ8E%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/dataprep/python_span_l_9b673a52-e3e1-4129-a2b2-0dc0d739809c.jsonl': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/dataprep/python_span_l_9b673a52-e3e1-4129-a2b2-0dc0d739809c.jsonl?sv=2019-02-02&sr=b&sig=SyB81w%2B90jcODQeimgo%2BTthScWiPYZlvjgK69jA8N4I%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=6fCPI0tbx5CWySy3ZuugRjKKIU%2Bbsr%2Bpu3ZCFxSBiPg%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=GlWKMSPn%2Bkmp5qYUme3prEDe%2BTbA%2B7yP3kmNA1AZmSw%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=eBSvSNfXU464GbokARuUQg4VVlOcSTnZs%2FAKkocspZU%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=bvl2V1Uhtved%2BUEXnYisQ6eo3GNdK5pxG3Cco%2BCGIWU%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.327d0507-d004-4017-9fde-f49b4761a284/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=AIgmntITxmLtL6AIdrEktJ5zelXrY6umvz476SoQHwo%3D&st=2020-11-25T10%3A17%3A42Z&se=2020-11-25T18%3A27%3A42Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: a57478ab-8bca-4e45-b82d-bcb60b5f3573\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/a57478ab-8bca-4e45-b82d-bcb60b5f3573?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "========================================================================================================================\n",
      "2020-11-25T10:28:06Z Starting output-watcher...\n",
      "2020-11-25T10:28:06Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-11-25T10:28:07Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-25T10:28:07Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      "Digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92\n",
      "Status: Image is up to date for ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020-11-25T10:28:08Z Check if container a57478ab-8bca-4e45-b82d-bcb60b5f3573 already exist exited with 0, \n",
      "\n",
      "59e545cc649a7c595538461dbc202a262e066c0f5beb4ce9b633320ecd37b8e9\n",
      "2020/11/25 10:28:10 Starting App Insight Logger for task:  containerSetup\n",
      "2020/11/25 10:28:10 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      "2020/11/25 10:28:10 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:28:10 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:28:10 sshd inside container not required for job, skipping setup.\n",
      "2020/11/25 10:28:10 All App Insights Logs was send successfully\n",
      "2020-11-25T10:28:10Z Starting docker container succeeded.\n",
      "2020-11-25T10:28:16Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2020/11/25 10:28:03 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/11/25 10:28:03 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      ">>>   2020/11/25 10:28:03 runtime.GOOS linux\n",
      ">>>   2020/11/25 10:28:03 Reading dyanamic configs\n",
      ">>>   2020/11/25 10:28:03 Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jCOdu9JYnzJiH4sLkyP8uB30%2BkOIOkA489fe%2BjeZkEs%3D\n",
      ">>>   2020/11/25 10:28:03 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2020/11/25 10:28:03 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2020/11/25 10:28:03 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2020/11/25 10:28:03 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2020/11/25 10:28:03 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2020/11/25 10:28:03 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2020/11/25 10:28:03 GPU count found: 0\n",
      ">>>   2020/11/25 10:28:03 AMLComputeXDSEndpoint:  https://eastus2-prodk8ds.batchai.core.windows.net\n",
      ">>>   2020/11/25 10:28:03 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2020/11/25 10:28:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config\n",
      ">>>   2020/11/25 10:28:03 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2020/11/25 10:28:03 Starting identity responder.\n",
      ">>>   2020/11/25 10:28:03 Starting identity responder.\n",
      ">>>   2020/11/25 10:28:03 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2020/11/25 10:28:03 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:28:03 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:28:03 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:28:03 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:28:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/wd\n",
      ">>>   2020/11/25 10:28:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/shared\n",
      ">>>   2020/11/25 10:28:03 Mounting job level file systems\n",
      ">>>   2020/11/25 10:28:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts\n",
      ">>>   2020/11/25 10:28:03 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/11/25 10:28:03 Datastore credentials file not found, skipping.\n",
      ">>>   2020/11/25 10:28:03 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config/.master.runtimesastokens\n",
      ">>>   2020/11/25 10:28:03 Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/11/25 10:28:03 No NFS configured\n",
      ">>>   2020/11/25 10:28:03 No Azure File Shares configured\n",
      ">>>   2020/11/25 10:28:03 Mounting blob file systems\n",
      ">>>   2020/11/25 10:28:03 Blobfuse runtime version blobfuse 1.3.5\n",
      ">>>   2020/11/25 10:28:03 Mounting azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:28:03 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:28:03 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:28:03 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2020/11/25 10:28:04 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:28:04 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:28:04 Successfully mounted azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:28:04 No unmanaged file systems configured\n",
      ">>>   2020/11/25 10:28:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs\n",
      ">>>   2020/11/25 10:28:05 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs\n",
      ">>>   2020/11/25 10:28:06 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/outputs\n",
      ">>>   2020/11/25 10:28:06 Starting output-watcher...\n",
      ">>>   2020/11/25 10:28:06 Single file input dataset is enabled.\n",
      ">>>   2020/11/25 10:28:06 Start to pulling docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:28:06 Start pull docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      ">>>   2020/11/25 10:28:06 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2020/11/25 10:28:06 Requesting XDS for registry details.\n",
      ">>>   2020/11/25 10:28:06 Attempt 1 of http call to https://eastus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/workspaces/nikhilsuthardp100/clusters/nikhilvmcluster/nodes/tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d?api-version=2018-02-01\n",
      ">>>   2020/11/25 10:28:07 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:07 Got container registry details from credentials service for registry address: ed4462f89ccc45679b9210c6758878a5.azurecr.io.\n",
      ">>>   2020/11/25 10:28:07 Writing ACR Details to file...\n",
      ">>>   2020/11/25 10:28:07 Copying ACR Details file to worker nodes...\n",
      ">>>   2020/11/25 10:28:07 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2020/11/25 10:28:07 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/11/25 10:28:07 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2020/11/25 10:28:07 EMS returned ed4462f89ccc45679b9210c6758878a5.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2020/11/25 10:28:07 Container registry is ACR.\n",
      ">>>   2020/11/25 10:28:07 start login to the docker registry\n",
      ">>>   2020/11/25 10:28:07 Successfully logged into the docker registry.\n",
      ">>>   2020/11/25 10:28:07 Start run pull docker image command\n",
      ">>>   2020/11/25 10:28:08 Pull docker image succeeded.\n",
      ">>>   2020/11/25 10:28:08 Pull docker image time: 1.721786526s\n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:08 Docker Version that this nodes use are: 19.03.13+azure\n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:08 Attempt 1 of http call to https://eastus2.experiments.azureml.net/history/v1.0/private/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/providers/Microsoft.MachineLearningServices/workspaces/nikhilsuthardp100/runs/a57478ab-8bca-4e45-b82d-bcb60b5f3573/spans\n",
      ">>>   2020/11/25 10:28:08 Setting the memory limit for docker container to be 13675 MB\n",
      ">>>   2020/11/25 10:28:08 The env variable file size is 36144 bytes\n",
      ">>>   2020/11/25 10:28:08 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/11/25 10:28:08 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name a57478ab-8bca-4e45-b82d-bcb60b5f3573 -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/certs:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -m 13675m -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573 -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/wd:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/a57478ab-8bca-4e45-b_71b7cbeb-f4a7-4259-8099-77c74eb740d9/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:28:08 Check if container a57478ab-8bca-4e45-b82d-bcb60b5f3573 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:08 Check if container a57478ab-8bca-4e45-b82d-bcb60b5f3573 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:10 Container ssh is not required for job type.\n",
      ">>>   2020/11/25 10:28:10 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:28:10 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:28:10 native cmd: cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2020/11/25 10:28:10 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t a57478ab-8bca-4e45-b82d-bcb60b5f3573 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573/mounts/workspaceblobstore/azureml/a57478ab-8bca-4e45-b82d-bcb60b5f3573-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.036674] Entering job preparation.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.706360] Starting job preparation.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.706498] Extracting the control code.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.724958] fetching and extracting the control code on master node.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.724988] Starting extract_project.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:11.725082] Starting to extract zip file.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:12.767444] Finished extracting zip file.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:12.920805] Using urllib.request Python 3.0 or later\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:12.920875] Start fetching snapshots.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:12.920931] Start fetching snapshot.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:12.920953] Retrieving project from snapshot: 5af7ce67-c6d7-4d64-96ee-7820e11f7625\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 49\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.609344] Finished fetching snapshot.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.609373] Finished fetching snapshots.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.609680] Finished extract_project.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.619760] Finished fetching and extracting the control code.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.622339] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.623612] Start run_history_prep.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:13.667786] Entering context manager injector.\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: Acquired lockfile /tmp/a57478ab-8bca-4e45-b82d-bcb60b5f3573-datastore.lock to downloading input data references\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:15.284499] downloadDataStore completed\n",
      ">>>   2020/11/25 10:28:15 runSpecialJobTask: preparation: [2020-11-25T10:28:15.287907] Job preparation is complete.\n",
      ">>>   2020/11/25 10:28:16 All App Insights Logs was send successfully\n",
      ">>>   2020/11/25 10:28:16 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-11-25T10:28:16Z 127.0.0.1 slots=2 max-slots=2\n",
      "2020-11-25T10:28:16Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "===============================================================================================================\n",
      "[2020-11-25T10:28:25.521958] Entering job release\n",
      "[2020-11-25T10:28:26.646912] Starting job release\n",
      "[2020-11-25T10:28:26.701839] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 139\n",
      "[2020-11-25T10:28:26.702451] job release stage : upload_datastore starting...\n",
      "[2020-11-25T10:28:26.706133] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-25T10:28:26.715261] job release stage : execute_job_release starting...\n",
      "[2020-11-25T10:28:26.715452] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-25T10:28:26.715488] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-25T10:28:26.716901] Entering context manager injector.\n",
      "[2020-11-25T10:28:26.967877] job release stage : send_run_telemetry starting...\n",
      "[2020-11-25T10:28:27.130645] job release stage : execute_job_release completed...\n",
      "[2020-11-25T10:28:27.202274] job release stage : upload_datastore completed...\n",
      "[2020-11-25T10:28:28.363840] job release stage : send_run_telemetry completed...\n",
      "[2020-11-25T10:28:28.364271] Job release is complete\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': 'a57478ab-8bca-4e45-b82d-bcb60b5f3573', 'target': 'nikhilvmcluster', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:28:07.010119Z', 'endTimeUtc': '2020-11-25T10:28:38.746199Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '5af7ce67-c6d7-4d64-96ee-7820e11f7625', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '5538de8b-7f8a-40bc-9bb0-8eb9268fae56', 'azureml.nodeid': 'c136bfe3', 'azureml.pipelinerunid': 'fa014266-d11a-4f39-b299-35392b892075', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'nikhilvmcluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/327d0507-d004-4017-9fde-f49b4761a284/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.18.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas'], 'name': 'azureml_76d0c57fc1c2b25401278bcbc2779419'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=VBEUIghah5nsRiO1pja3hLb7prDBsB3E9FG9rH76bZI%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=TLwK5qrv749F9OLk2RMwA6W7Vz1RK8gBfaBP5Sx68ho%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=45OJiFGBegICkMoDxyLE6u47PV8jrHIowBHbSDzWXYI%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=AO4oaHHVgSlFFHohm9C0y%2BpFUiIzY8B5A0%2BqufMp18g%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'azureml-logs/process_info.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=HiH6NHBpLoia1xp6uudDUIAyrVgJwnYhb3ucDqzD1yU%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'azureml-logs/process_status.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=hZ4qxn7Sx8hvRWtsKm%2BIHTPATQ7C5dWNreRZzoGF%2Bgk%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/102_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/102_azureml.log?sv=2019-02-02&sr=b&sig=%2FvijqTjgncFYylzJVCJF%2BbeDpJrfHtFBUOKgLV3Q6as%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ANsUsTM5ORKUQqj8G9nQAEN2T6edgimBwTVWKX8ic7I%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=HAc%2BNXPhMCgEJLLVmPbT%2FZ4HnxrMwsTwVVbgk%2FvZ4ZQ%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=gwmca%2Bw6T657cWef0Jb9mAzqKFsZLV69qL9Gs8CQDAg%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Er%2Fs42NkO1AgWmGwaljp53Mvybu8xFlC5rVeu21O6Tg%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.a57478ab-8bca-4e45-b82d-bcb60b5f3573/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Ehvj6VDK42%2FlT86NIU7DZAfQyfmo%2FQnM6mz74Yrthao%3D&st=2020-11-25T10%3A18%3A30Z&se=2020-11-25T18%3A28%3A30Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'fa014266-d11a-4f39-b299-35392b892075', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:15:00.881715Z', 'endTimeUtc': '2020-11-25T10:28:47.316608Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.fa014266-d11a-4f39-b299-35392b892075/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=TmskTn1Sp9H2hw1IDAcM8RigB7Nr%2FTIEJbTIXyQOV38%3D&st=2020-11-25T10%3A05%3A08Z&se=2020-11-25T18%3A15%3A08Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.fa014266-d11a-4f39-b299-35392b892075/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=L8gITAP4j12xIJ%2B0HwciAHaqsZbJs2AE48xTKDx2NfE%3D&st=2020-11-25T10%3A05%3A08Z&se=2020-11-25T18%3A15%3A08Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.fa014266-d11a-4f39-b299-35392b892075/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=xhuUUm3XskaNinuD3fRNxaWyW%2BarEf634JHTEJcGN6E%3D&st=2020-11-25T10%3A05%3A08Z&se=2020-11-25T18%3A15%3A08Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the pipeline experiment will be displayed as it runs. keep an eye on the kernel indicator at the top right of the page, when it turns from **&#9899;** to **&#9711;**, the code has finished running. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "When the pipeline has finished, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 3\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized SKLearn Estimator\n",
      "\t AUC : 0.8483904671874223\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "amlstudio-predict-diabetes version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-predict-auto-price version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "AutoMLcd52161af2 version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline\n",
    "\n",
    "Now that you've created a pipeline and verified it works, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eastus2.api.azureml.ms/pipelines/v1.0/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/providers/Microsoft.MachineLearningServices/workspaces/nikhilsuthardp100/PipelineRuns/PipelineSubmit/07a089a6-aef4-416e-a1a2-b708f43cb3bc\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Diabetes_Training_Pipeline\",\n",
    "                                      description=\"Trains diabetes model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to call the REST interface. The pipeline runs asynchronously, so you'll get an identifier back, which you can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c779854e-d68d-4a06-bdaa-8a0279faae58'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "experiment_name = 'Run-diabetes-pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use it to wait for the run to complete.\n",
    "\n",
    "> **Note**: The pipeline should complete quickly, because each step was configured to allow output reuse. This was done primarily for convenience and to save time in this example. In reality, you'd likely want the first step to run every time in case the data has changed, and trigger the subsequent steps only if the output from step one changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: c779854e-d68d-4a06-bdaa-8a0279faae58\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Run-diabetes-pipeline/runs/c779854e-d68d-4a06-bdaa-8a0279faae58?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: f137d214-f2e7-4b84-92f8-8aa5e708ae31\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Run-diabetes-pipeline/runs/f137d214-f2e7-4b84-92f8-8aa5e708ae31?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "========================================================================================================================\n",
      "2020-11-25T10:30:24Z Starting output-watcher...\n",
      "2020-11-25T10:30:24Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "StepRun( Train Model ) Status: Running\n",
      "2020-11-25T10:30:24Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-25T10:30:24Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      "Digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92\n",
      "Status: Image is up to date for ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020-11-25T10:30:26Z Check if container f137d214-f2e7-4b84-92f8-8aa5e708ae31 already exist exited with 0, \n",
      "\n",
      "223a3af5dd18717f309e6577ea4c5d640ecea62c6ef29b2727801a35d6afdf16\n",
      "2020/11/25 10:30:27 Starting App Insight Logger for task:  containerSetup\n",
      "2020/11/25 10:30:27 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      "2020/11/25 10:30:27 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:30:27 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:30:27 sshd inside container not required for job, skipping setup.\n",
      "2020/11/25 10:30:27 All App Insights Logs was send successfully\n",
      "2020-11-25T10:30:27Z Starting docker container succeeded.\n",
      "2020-11-25T10:30:34Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2020/11/25 10:30:21 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/11/25 10:30:21 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      ">>>   2020/11/25 10:30:21 runtime.GOOS linux\n",
      ">>>   2020/11/25 10:30:21 Reading dyanamic configs\n",
      ">>>   2020/11/25 10:30:21 Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jCOdu9JYnzJiH4sLkyP8uB30%2BkOIOkA489fe%2BjeZkEs%3D\n",
      ">>>   2020/11/25 10:30:21 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2020/11/25 10:30:21 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2020/11/25 10:30:21 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2020/11/25 10:30:21 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2020/11/25 10:30:21 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2020/11/25 10:30:21 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2020/11/25 10:30:21 GPU count found: 0\n",
      ">>>   2020/11/25 10:30:21 AMLComputeXDSEndpoint:  https://eastus2-prodk8ds.batchai.core.windows.net\n",
      ">>>   2020/11/25 10:30:21 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2020/11/25 10:30:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config\n",
      ">>>   2020/11/25 10:30:21 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2020/11/25 10:30:21 Starting identity responder.\n",
      ">>>   2020/11/25 10:30:21 Starting identity responder.\n",
      ">>>   2020/11/25 10:30:21 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2020/11/25 10:30:21 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:30:21 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:30:21 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:30:21 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:30:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/wd\n",
      ">>>   2020/11/25 10:30:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/shared\n",
      ">>>   2020/11/25 10:30:21 Mounting job level file systems\n",
      ">>>   2020/11/25 10:30:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts\n",
      ">>>   2020/11/25 10:30:21 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/11/25 10:30:21 Datastore credentials file not found, skipping.\n",
      ">>>   2020/11/25 10:30:21 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config/.master.runtimesastokens\n",
      ">>>   2020/11/25 10:30:21 Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/11/25 10:30:21 No NFS configured\n",
      ">>>   2020/11/25 10:30:21 No Azure File Shares configured\n",
      ">>>   2020/11/25 10:30:21 Mounting blob file systems\n",
      ">>>   2020/11/25 10:30:21 Blobfuse runtime version blobfuse 1.3.5\n",
      ">>>   2020/11/25 10:30:21 Mounting azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:30:21 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:30:21 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:30:21 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2020/11/25 10:30:21 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:30:21 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:30:21 Successfully mounted azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:30:21 No unmanaged file systems configured\n",
      ">>>   2020/11/25 10:30:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs\n",
      ">>>   2020/11/25 10:30:22 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs\n",
      ">>>   2020/11/25 10:30:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/outputs\n",
      ">>>   2020/11/25 10:30:24 Starting output-watcher...\n",
      ">>>   2020/11/25 10:30:24 Single file input dataset is enabled.\n",
      ">>>   2020/11/25 10:30:24 Start to pulling docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:30:24 Start pull docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      ">>>   2020/11/25 10:30:24 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2020/11/25 10:30:24 Requesting XDS for registry details.\n",
      ">>>   2020/11/25 10:30:24 Attempt 1 of http call to https://eastus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/workspaces/nikhilsuthardp100/clusters/nikhilvmcluster/nodes/tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d?api-version=2018-02-01\n",
      ">>>   2020/11/25 10:30:24 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:24 Got container registry details from credentials service for registry address: ed4462f89ccc45679b9210c6758878a5.azurecr.io.\n",
      ">>>   2020/11/25 10:30:24 Writing ACR Details to file...\n",
      ">>>   2020/11/25 10:30:24 Copying ACR Details file to worker nodes...\n",
      ">>>   2020/11/25 10:30:24 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2020/11/25 10:30:24 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/11/25 10:30:25 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2020/11/25 10:30:25 EMS returned ed4462f89ccc45679b9210c6758878a5.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2020/11/25 10:30:25 Container registry is ACR.\n",
      ">>>   2020/11/25 10:30:25 start login to the docker registry\n",
      ">>>   2020/11/25 10:30:25 Successfully logged into the docker registry.\n",
      ">>>   2020/11/25 10:30:25 Start run pull docker image command\n",
      ">>>   2020/11/25 10:30:25 Pull docker image succeeded.\n",
      ">>>   2020/11/25 10:30:25 Pull docker image time: 1.402492178s\n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:25 Docker Version that this nodes use are: 19.03.13+azure\n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:26 Setting the memory limit for docker container to be 13675 MB\n",
      ">>>   2020/11/25 10:30:26 The env variable file size is 36774 bytes\n",
      ">>>   2020/11/25 10:30:26 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/11/25 10:30:26 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name f137d214-f2e7-4b84-92f8-8aa5e708ae31 -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/certs:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -m 13675m -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31 -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/wd:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/f137d214-f2e7-4b84-9_66520e11-2b3c-4e92-939f-39612a596208/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:30:26 Check if container f137d214-f2e7-4b84-92f8-8aa5e708ae31 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:26 Check if container f137d214-f2e7-4b84-92f8-8aa5e708ae31 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:26 Attempt 1 of http call to https://eastus2.experiments.azureml.net/history/v1.0/private/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/providers/Microsoft.MachineLearningServices/workspaces/nikhilsuthardp100/runs/f137d214-f2e7-4b84-92f8-8aa5e708ae31/spans\n",
      ">>>   2020/11/25 10:30:27 Container ssh is not required for job type.\n",
      ">>>   2020/11/25 10:30:27 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:30:27 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:30:27 native cmd: cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2020/11/25 10:30:27 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t f137d214-f2e7-4b84-92f8-8aa5e708ae31 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.315354] Entering job preparation.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.950752] Starting job preparation.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.950786] Extracting the control code.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.971783] fetching and extracting the control code on master node.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.971825] Starting extract_project.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:28.971885] Starting to extract zip file.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:29.876870] Finished extracting zip file.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.005658] Using urllib.request Python 3.0 or later\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.005733] Start fetching snapshots.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.005787] Start fetching snapshot.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.005808] Retrieving project from snapshot: 5af7ce67-c6d7-4d64-96ee-7820e11f7625\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 52\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.414783] Finished fetching snapshot.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.414811] Finished fetching snapshots.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.414830] Finished extract_project.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.425147] Finished fetching and extracting the control code.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.428928] Start run_history_prep.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.429065] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:30.475723] Entering context manager injector.\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: Acquired lockfile /tmp/f137d214-f2e7-4b84-92f8-8aa5e708ae31-datastore.lock to downloading input data references\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:32.368905] downloadDataStore completed\n",
      ">>>   2020/11/25 10:30:32 runSpecialJobTask: preparation: [2020-11-25T10:30:32.373817] Job preparation is complete.\n",
      ">>>   2020/11/25 10:30:34 All App Insights Logs was send successfully\n",
      ">>>   2020/11/25 10:30:34 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-11-25T10:30:34Z 127.0.0.1 slots=2 max-slots=2\n",
      "2020-11-25T10:30:34Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/11/25 10:30:35 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2020/11/25 10:30:35 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2020-11-25T10:30:36.500471] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train_diabetes.py', '--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/model_folder'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 106\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31\n",
      "Preparing to call script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/model_folder']\n",
      "After variable expansion, calling script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/mounts/workspaceblobstore/azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/model_folder']\n",
      "\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8997777777777778\n",
      "AUC: 0.8850826091996026\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 106\n",
      "\n",
      "\n",
      "[2020-11-25T10:30:49.999377] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.5320496559143066 seconds\n",
      "[2020-11-25T10:30:51.431003] Finished context manager injector.\n",
      "2020/11/25 10:30:55 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2020/11/25 10:30:55 Process Exiting with Code:  0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "===============================================================================================================\n",
      "[2020-11-25T10:30:56.286622] Entering job release\n",
      "[2020-11-25T10:30:57.227937] Starting job release\n",
      "[2020-11-25T10:30:57.228703] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 323\n",
      "[2020-11-25T10:30:57.229219] job release stage : upload_datastore starting...\n",
      "[2020-11-25T10:30:57.238668] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-25T10:30:57.239484] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-25T10:30:57.239717] job release stage : execute_job_release starting...\n",
      "[2020-11-25T10:30:57.239622] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-25T10:30:57.240468] Entering context manager injector.\n",
      "[2020-11-25T10:30:57.446850] job release stage : upload_datastore completed...\n",
      "[2020-11-25T10:30:57.628744] job release stage : execute_job_release completed...\n",
      "[2020-11-25T10:30:57.863931] job release stage : send_run_telemetry starting...\n",
      "[2020-11-25T10:31:00.238207] job release stage : send_run_telemetry completed...\n",
      "[2020-11-25T10:31:00.238682] Job release is complete\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': 'f137d214-f2e7-4b84-92f8-8aa5e708ae31', 'target': 'nikhilvmcluster', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:30:21.735136Z', 'endTimeUtc': '2020-11-25T10:31:06.424581Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '5af7ce67-c6d7-4d64-96ee-7820e11f7625', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '07bd421b-156f-4fcb-9659-c969f786c8f1', 'azureml.nodeid': '590f6e0b', 'azureml.pipelinerunid': 'c779854e-d68d-4a06-bdaa-8a0279faae58', 'azureml.pipelineid': '07a089a6-aef4-416e-a1a2-b708f43cb3bc', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '47094f00-3593-45f5-97d5-f8ebb5db829c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'nikhilvmcluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': '47094f00-3593-45f5-97d5-f8ebb5db829c', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.18.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas'], 'name': 'azureml_76d0c57fc1c2b25401278bcbc2779419'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=aPptUsKYiwraJMCOWPGKp%2FcSNNKdLbKmBSJ8MNjZpmg%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=lOK4seIl%2BpprJdpysJhtpzfWjTHO4jY8IVf2648B2fU%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=FabSri73d%2FMytmQbzvYYcF8UTCiHeHfCCc34P5kov4A%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=aA0tPMuzbSMymoneg2jvFkrIE1AKQPYBX6mxRvvL2sk%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'azureml-logs/process_info.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=bNYz5Ulxe0jm3MhOdpYuJKqTOcdQV7rZ6sKKSrBTaiA%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'azureml-logs/process_status.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=fmckW6CFAAHnvt%2BIvx9I7xjrwg0L8SfmpLtYfAWC5J4%3D&st=2020-11-25T10%3A21%3A03Z&se=2020-11-25T18%3A31%3A03Z&sp=r', 'logs/azureml/106_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=ieN%2BWQsO7QwceC8UQi3tcODCo9NYPBCA7yytnQsgAPw%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=v3IaQ4mfyE3N%2FpKKAniqNWzqKqjKc%2B9u29jj%2FthmwRA%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=J6GJgla%2FZv71xuaNkwpXnF9G9g3vLTFz0cwKlWfgyq0%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/dataprep/engine_spans_l_e383ded9-0a11-43cf-b48a-4bee86364d78.jsonl': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/dataprep/engine_spans_l_e383ded9-0a11-43cf-b48a-4bee86364d78.jsonl?sv=2019-02-02&sr=b&sig=7JsYYIcVIarEA5I%2BBVcx3LYfnPRmf3Clw%2BwF933OZkQ%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/dataprep/python_span_l_e383ded9-0a11-43cf-b48a-4bee86364d78.jsonl': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/dataprep/python_span_l_e383ded9-0a11-43cf-b48a-4bee86364d78.jsonl?sv=2019-02-02&sr=b&sig=aUGSXYERgQfY5Cf4dUXnitmxTow%2BRdFOXaeJyOcK5BU%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=cNzsE4Il9G9wuxUR4HxLvZ8tf1dAIeXIxG5WcY3D8WA%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=2dzfkmd8rtCq%2Fdr4sNZXDC9ZzoNlvlJetsrTktq2UJM%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=WY7g%2FDIRB2TCb%2Bg2zsx77ILlXxY6%2BXNtAnuYFRNzZjU%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=8LYjUSH%2BxM74Gkpr9UnwdK%2FwLW5ebFxdpj1hcH2Qo6E%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.f137d214-f2e7-4b84-92f8-8aa5e708ae31/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Xh2OPgQr187%2B3g3JqQfMo5mjDOke0Z2dwhjr0NLWrwo%3D&st=2020-11-25T10%3A21%3A02Z&se=2020-11-25T18%3A31%3A02Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 8a79253b-2dd7-4503-b45a-f85714ed873d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Run-diabetes-pipeline/runs/8a79253b-2dd7-4503-b45a-f85714ed873d?wsid=/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourcegroups/nikhil-suthardp100/workspaces/nikhilsuthardp100\n",
      "StepRun( Register Model ) Status: NotStarted\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "========================================================================================================================\n",
      "2020-11-25T10:31:33Z Starting output-watcher...\n",
      "2020-11-25T10:31:33Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-11-25T10:31:33Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-25T10:31:33Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      "Digest: sha256:e24632faa61a197298cfbb748d9f148fcce15d72ec2c97c3cae1ab06f89a0a92\n",
      "Status: Image is up to date for ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37:latest\n",
      "2020-11-25T10:31:35Z Check if container 8a79253b-2dd7-4503-b45a-f85714ed873d already exist exited with 0, \n",
      "\n",
      "ca53d59e4b494cb479df721ab1f002f3ab2e9a2ad9e1de9c9dd0f71cacc049a2\n",
      "2020/11/25 10:31:35 Starting App Insight Logger for task:  containerSetup\n",
      "2020/11/25 10:31:35 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      "2020/11/25 10:31:35 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:31:35 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/11/25 10:31:35 sshd inside container not required for job, skipping setup.\n",
      "2020/11/25 10:31:36 All App Insights Logs was send successfully\n",
      "2020-11-25T10:31:37Z Starting docker container succeeded.\n",
      "2020-11-25T10:31:41Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2020/11/25 10:31:30 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2020/11/25 10:31:30 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      ">>>   2020/11/25 10:31:30 runtime.GOOS linux\n",
      ">>>   2020/11/25 10:31:30 Reading dyanamic configs\n",
      ">>>   2020/11/25 10:31:30 Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jCOdu9JYnzJiH4sLkyP8uB30%2BkOIOkA489fe%2BjeZkEs%3D\n",
      ">>>   2020/11/25 10:31:30 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2020/11/25 10:31:30 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2020/11/25 10:31:30 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2020/11/25 10:31:30 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2020/11/25 10:31:30 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2020/11/25 10:31:30 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2020/11/25 10:31:30 GPU count found: 0\n",
      ">>>   2020/11/25 10:31:30 AMLComputeXDSEndpoint:  https://eastus2-prodk8ds.batchai.core.windows.net\n",
      ">>>   2020/11/25 10:31:30 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2020/11/25 10:31:30 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config\n",
      ">>>   2020/11/25 10:31:30 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2020/11/25 10:31:30 Starting identity responder.\n",
      ">>>   2020/11/25 10:31:30 Starting identity responder.\n",
      ">>>   2020/11/25 10:31:30 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2020/11/25 10:31:30 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:30 Logfile used for identity responder: /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/IdentityResponderLog-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:30 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:31:30 Started Identity Responder for job.\n",
      ">>>   2020/11/25 10:31:30 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/wd\n",
      ">>>   2020/11/25 10:31:30 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/shared\n",
      ">>>   2020/11/25 10:31:30 Mounting job level file systems\n",
      ">>>   2020/11/25 10:31:30 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts\n",
      ">>>   2020/11/25 10:31:30 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config/.amlcompute.datastorecredentials\n",
      ">>>   2020/11/25 10:31:30 Datastore credentials file not found, skipping.\n",
      ">>>   2020/11/25 10:31:30 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config/.master.runtimesastokens\n",
      ">>>   2020/11/25 10:31:30 Runtime sas tokens file not found, skipping.\n",
      ">>>   2020/11/25 10:31:30 No NFS configured\n",
      ">>>   2020/11/25 10:31:30 No Azure File Shares configured\n",
      ">>>   2020/11/25 10:31:30 Mounting blob file systems\n",
      ">>>   2020/11/25 10:31:30 Blobfuse runtime version blobfuse 1.3.5\n",
      ">>>   2020/11/25 10:31:30 Mounting azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:31:30 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:31:30 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2020/11/25 10:31:30 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2020/11/25 10:31:30 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:31:30 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:31:30 Successfully mounted azureml-blobstore-ed4462f8-9ccc-4567-9b92-10c6758878a5 container from nikhilsuthardp7211953111 account at /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore\n",
      ">>>   2020/11/25 10:31:30 No unmanaged file systems configured\n",
      ">>>   2020/11/25 10:31:30 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs\n",
      ">>>   2020/11/25 10:31:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/logs\n",
      ">>>   2020/11/25 10:31:32 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/outputs\n",
      ">>>   2020/11/25 10:31:33 Starting output-watcher...\n",
      ">>>   2020/11/25 10:31:33 Single file input dataset is enabled.\n",
      ">>>   2020/11/25 10:31:33 Start to pulling docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:31:33 Start pull docker image: ed4462f89ccc45679b9210c6758878a5.azurecr.io\n",
      ">>>   2020/11/25 10:31:33 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2020/11/25 10:31:33 Requesting XDS for registry details.\n",
      ">>>   2020/11/25 10:31:33 Attempt 1 of http call to https://eastus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/workspaces/nikhilsuthardp100/clusters/nikhilvmcluster/nodes/tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d?api-version=2018-02-01\n",
      ">>>   2020/11/25 10:31:33 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:33 Got container registry details from credentials service for registry address: ed4462f89ccc45679b9210c6758878a5.azurecr.io.\n",
      ">>>   2020/11/25 10:31:33 Writing ACR Details to file...\n",
      ">>>   2020/11/25 10:31:33 Copying ACR Details file to worker nodes...\n",
      ">>>   2020/11/25 10:31:33 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2020/11/25 10:31:33 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2020/11/25 10:31:33 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2020/11/25 10:31:33 EMS returned ed4462f89ccc45679b9210c6758878a5.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2020/11/25 10:31:33 Container registry is ACR.\n",
      ">>>   2020/11/25 10:31:33 start login to the docker registry\n",
      ">>>   2020/11/25 10:31:34 Successfully logged into the docker registry.\n",
      ">>>   2020/11/25 10:31:34 Start run pull docker image command\n",
      ">>>   2020/11/25 10:31:34 Pull docker image succeeded.\n",
      ">>>   2020/11/25 10:31:34 Pull docker image time: 1.087972798s\n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:34 Docker Version that this nodes use are: 19.03.13+azure\n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:34 Setting the memory limit for docker container to be 13675 MB\n",
      ">>>   2020/11/25 10:31:34 The env variable file size is 36113 bytes\n",
      ">>>   2020/11/25 10:31:34 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2020/11/25 10:31:34 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 8a79253b-2dd7-4503-b45a-f85714ed873d -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/certs:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/certs -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -m 13675m -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs -v /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d:/mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d -v /mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/wd:/mnt/batch/tasks/workitems/6d684a26-cef9-41c7-9a28-b0a27a0f95dc/job-1/8a79253b-2dd7-4503-b_9b4c896e-6358-45cd-b531-c73d62521fe5/wd -v /opt/azureml:/opt/azureml:ro -w /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/config/.batchai.envlist --shm-size 2g -d -it --privileged --net=host ed4462f89ccc45679b9210c6758878a5.azurecr.io/azureml/azureml_4c436a746d1f86e10a04b3459370ec37\n",
      ">>>   2020/11/25 10:31:35 Check if container 8a79253b-2dd7-4503-b45a-f85714ed873d already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:35 Check if container 8a79253b-2dd7-4503-b45a-f85714ed873d already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:35 Attempt 1 of http call to https://eastus2.experiments.azureml.net/history/v1.0/private/subscriptions/71bfcf50-7e10-4546-9c9a-fd4f1ee42434/resourceGroups/nikhil-suthardp100/providers/Microsoft.MachineLearningServices/workspaces/nikhilsuthardp100/runs/8a79253b-2dd7-4503-b45a-f85714ed873d/spans\n",
      ">>>   2020/11/25 10:31:37 Container ssh is not required for job type.\n",
      ">>>   2020/11/25 10:31:37 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:31:37 Starting docker container succeeded.\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:37 native cmd: cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2020/11/25 10:31:37 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t 8a79253b-2dd7-4503-b45a-f85714ed873d bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d;/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"5af7ce67-c6d7-4d64-96ee-7820e11f7625\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:37.589053] Entering job preparation.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:38.324189] Starting job preparation.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:38.324235] Extracting the control code.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:38.343549] fetching and extracting the control code on master node.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:38.343617] Starting extract_project.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:38.343708] Starting to extract zip file.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.036312] Finished extracting zip file.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.182188] Using urllib.request Python 3.0 or later\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.182256] Start fetching snapshots.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.182310] Start fetching snapshot.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.182333] Retrieving project from snapshot: 5af7ce67-c6d7-4d64-96ee-7820e11f7625\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 48\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.565235] Finished fetching snapshot.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.565273] Finished fetching snapshots.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.565287] Finished extract_project.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.577376] Finished fetching and extracting the control code.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.580257] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.581551] Start run_history_prep.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:39.639597] Entering context manager injector.\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: Acquired lockfile /tmp/8a79253b-2dd7-4503-b45a-f85714ed873d-datastore.lock to downloading input data references\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:40.740668] downloadDataStore completed\n",
      ">>>   2020/11/25 10:31:40 runSpecialJobTask: preparation: [2020-11-25T10:31:40.745727] Job preparation is complete.\n",
      ">>>   2020/11/25 10:31:41 All App Insights Logs was send successfully\n",
      ">>>   2020/11/25 10:31:41 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2020-11-25T10:31:41Z 127.0.0.1 slots=2 max-slots=2\n",
      "2020-11-25T10:31:41Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-25T10:31:49Z job exited with code 0\n",
      "2020-11-25T10:31:50Z Executing 'JobRelease task' on 10.0.0.5\n",
      "2020-11-25T10:31:54Z JobRelease task succeeded on 10.0.0.5. Output: \n",
      ">>>   2020/11/25 10:31:50 Starting App Insight Logger for task:  jobRelease\n",
      ">>>   2020/11/25 10:31:50 Version: 3.0.01417.0012 Branch: 56 Commit: d244ddd\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml_compute_logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      ">>>   2020/11/25 10:31:50 native cmd: cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2020/11/25 10:31:50 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t 8a79253b-2dd7-4503-b45a-f85714ed873d bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;cd /mnt/batch/tasks/shared/LS_root/jobs/nikhilsuthardp100/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/mounts/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_76d0c57fc1c2b25401278bcbc2779419/bin/python $AZ_BATCHAI_JOB_MOUNT_ROOT/workspaceblobstore/azureml/8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:50.520891] Entering job release\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.419263] Starting job release\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.425061] Logging experiment finalizing status in history service.\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.425188] job release stage : upload_datastore starting...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: Starting the daemon thread to refresh tokens in background for process with pid = 133\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.425480] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.426091] job release stage : copy_batchai_cached_logs starting...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.426136] job release stage : copy_batchai_cached_logs completed...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.426437] job release stage : execute_job_release starting...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.428810] Entering context manager injector.\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:51.947170] job release stage : upload_datastore completed...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:52.188428] job release stage : execute_job_release completed...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:52.296081] job release stage : send_run_telemetry starting...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:54.007901] job release stage : send_run_telemetry completed...\n",
      ">>>   2020/11/25 10:31:54 runSpecialJobTask: postprocessing: [2020-11-25T10:31:54.008368] Job release is complete\n",
      ">>>   2020/11/25 10:31:54 All App Insights Logs was send successfully\n",
      ">>>   \n",
      "2020-11-25T10:31:54Z Executing 'Job environment clean-up' on 10.0.0.5\n",
      "2020-11-25T10:31:54Z Removing container 8a79253b-2dd7-4503-b45a-f85714ed873d exited with 0, 8a79253b-2dd7-4503-b45a-f85714ed873d\n",
      "\n",
      "\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt\n",
      "===============================================================================================================\n",
      "[2020-11-25T10:31:50.520891] Entering job release\n",
      "[2020-11-25T10:31:51.419263] Starting job release\n",
      "[2020-11-25T10:31:51.425061] Logging experiment finalizing status in history service.\n",
      "[2020-11-25T10:31:51.425188] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 133\n",
      "[2020-11-25T10:31:51.425480] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-11-25T10:31:51.426091] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-11-25T10:31:51.426136] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-11-25T10:31:51.426437] job release stage : execute_job_release starting...\n",
      "[2020-11-25T10:31:51.428810] Entering context manager injector.\n",
      "[2020-11-25T10:31:51.947170] job release stage : upload_datastore completed...\n",
      "[2020-11-25T10:31:52.188428] job release stage : execute_job_release completed...\n",
      "[2020-11-25T10:31:52.296081] job release stage : send_run_telemetry starting...\n",
      "[2020-11-25T10:31:54.007901] job release stage : send_run_telemetry completed...\n",
      "[2020-11-25T10:31:54.008368] Job release is complete\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': '8a79253b-2dd7-4503-b45a-f85714ed873d', 'target': 'nikhilvmcluster', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:31:35.181777Z', 'endTimeUtc': '2020-11-25T10:32:00.353441Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '5af7ce67-c6d7-4d64-96ee-7820e11f7625', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '5538de8b-7f8a-40bc-9bb0-8eb9268fae56', 'azureml.nodeid': 'c136bfe3', 'azureml.pipelinerunid': 'c779854e-d68d-4a06-bdaa-8a0279faae58', 'azureml.pipelineid': '07a089a6-aef4-416e-a1a2-b708f43cb3bc', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'nikhilvmcluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/f137d214-f2e7-4b84-92f8-8aa5e708ae31/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.18.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas'], 'name': 'azureml_76d0c57fc1c2b25401278bcbc2779419'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/55_azureml-execution-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=T8FVZtDpdoGIyMhrrzS2ftbkAbllxcv6ASN2ZA0Bqdk%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/65_job_prep-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=TwQghwmXy%2FCUo5WA33oJG%2FGzYosucuy5DhUaeQ%2B5qdk%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=1wosrhn4KJFjOpHfxpmT2r4yFk8FaYAr1osj%2FTOI7w8%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/75_job_post-tvmps_a527a08f0b4e0c38d884e9d58aae7f365886dabc5956acd3a998d99c4ff0eb71_d.txt?sv=2019-02-02&sr=b&sig=M7Y1Ksf%2F9s8PbIB72DRWEeJOqqcyFLJfrjvOzc44NaI%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'azureml-logs/process_info.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=vzFlqNnhYhvIy2GOBvnG%2FVjVQViGDw0nb6DawH%2FP%2FGs%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'azureml-logs/process_status.json': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=CdT%2FCCXB7atgC%2FlcjzG6PwgzPZcIuq0xYLFZPf9yM9E%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/102_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/102_azureml.log?sv=2019-02-02&sr=b&sig=F%2Feypce%2FYylyndG2TLonkNE%2BAlf3iXOKzoUivUbmmiA%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=IZc%2FDy7TlAal2RMdZ5PGSIU73w%2Fg4MpUf6PnQa768J4%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=u4xEyn5ugthTlle4Kl7XBRMN1un7p0kivHQ%2BbntdkA4%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=3o3PwYQtqBnYva%2Bn4%2BQgcp%2FTSWvdFdWb%2F0MeOLCIwtU%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Gu2TjuNo1ycv%2Fqi8Lfbx2wpD%2F%2BYNSfP05jwGANKqaBM%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.8a79253b-2dd7-4503-b45a-f85714ed873d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=quoRPA%2FLaemdSmXAh0CsBKH9YfAHmicjKaeKHE6ltWc%3D&st=2020-11-25T10%3A21%3A56Z&se=2020-11-25T18%3A31%3A56Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'c779854e-d68d-4a06-bdaa-8a0279faae58', 'status': 'Completed', 'startTimeUtc': '2020-11-25T10:29:57.402105Z', 'endTimeUtc': '2020-11-25T10:32:06.580729Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '07a089a6-aef4-416e-a1a2-b708f43cb3bc'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.c779854e-d68d-4a06-bdaa-8a0279faae58/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=722N70E0Qu8ov362XvqzTTLukTrZHQjeA0osk9BlESU%3D&st=2020-11-25T10%3A20%3A32Z&se=2020-11-25T18%3A30%3A32Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.c779854e-d68d-4a06-bdaa-8a0279faae58/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=6H2vBwonVIwDxeLPz%2BuXk4Wcuy%2FBG6WVGZC1N0IuTAo%3D&st=2020-11-25T10%3A20%3A32Z&se=2020-11-25T18%3A30%3A32Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://nikhilsuthardp7211953111.blob.core.windows.net/azureml/ExperimentRun/dcid.c779854e-d68d-4a06-bdaa-8a0279faae58/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=rh32NKcYNGp1fIsLD1AV54KrrWopeqnj2HY3aJdrusI%3D&st=2020-11-25T10%3A20%3A32Z&se=2020-11-25T18%3A30%3A32Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
    "\n",
    "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
